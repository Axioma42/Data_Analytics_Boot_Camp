{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Load Amazon Data into Spark DataFrame"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pyspark\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Video_Games_v1_00.tsv.gz\"\n",
        "spark.sparkContext.addFile(url)\n",
        "video_games_df = spark.read.csv(SparkFiles.get(\"amazon_reviews_us_Video_Games_v1_00.tsv.gz\"), sep=\"\\t\", header=True)\n",
        "video_games_df.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Size of data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pyspark\n",
        "# Row Count\n",
        "video_games_df.count()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaned up DataFrames to match tables"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pyspark\n",
        "from pyspark.sql.functions import to_date\n",
        "# Review DataFrame\n",
        "review_id_df = video_games_df.select([\"review_id\", \"customer_id\", \"product_id\", \"product_parent\", to_date(\"review_date\", 'yyyy-MM-dd').alias(\"review_date\")])\n",
        "review_id_df.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pyspark\n",
        "products_df = video_games_df.select([\"product_id\", \"product_title\"]).drop_duplicates()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pyspark\n",
        "reviews_df = video_games_df.select([\"review_id\", \"review_headline\", \"review_body\"])\n",
        "reviews_df.show(10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pyspark\n",
        "customers_df = video_games_df.groupby(\"customer_id\").agg({\"customer_id\": \"count\"}).withColumnRenamed(\"count(customer_id)\", \"customer_count\")\n",
        "customers_df.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pyspark\n",
        "vine_df = video_games_df.select([\"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", \"vine\"])\n",
        "vine_df.show(10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Push to AWS RDS instance"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pyspark\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://<endpoint>:5432/my_data_class_db\"\n",
        "config = {\"user\":\"root\", \"password\": \"<password>\", \"driver\":\"org.postgresql.Driver\"}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pyspark\n",
        "# Write review_id_df to table in RDS\n",
        "review_id_df.write.jdbc(url=jdbc_url, table='review_id_table', mode=mode, properties=config)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pyspark\n",
        "# Write products_df to table in RDS\n",
        "products_df.write.jdbc(url=jdbc_url, table='products', mode=mode, properties=config)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pyspark\n",
        "# Write customers_df to table in RDS\n",
        "customers_df.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pyspark\n",
        "# Write vine_df to table in RDS\n",
        "vine_df.write.jdbc(url=jdbc_url, table='vines', mode=mode, properties=config)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pydev",
      "language": "python",
      "name": "pydev"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}